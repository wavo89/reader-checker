===== ./app.py =====
from flask import Flask, request, jsonify, render_template, send_from_directory
import openai
import os
import subprocess
import pathlib
from utils.calculate_accuracy import calculate_accuracy, preprocess_text
import json

app = Flask(__name__)
openai.api_key = os.getenv("OPENAI_API_KEY")


@app.route("/")
def index():
    scene_id = request.args.get("scene", "hex1")
    with open("scenes/scenes.json", "r") as f:
        scenes = json.load(f)
        scene = scenes.get(scene_id, scenes["hex1"])
    return render_template("index.html", scene=scene, scene_id=scene_id)


@app.route("/scenes/<filename>")
def serve_scene_file(filename):
    return send_from_directory("scenes", filename)


@app.route("/transcribe-audio", methods=["POST"])
def transcribe_audio():
    audio_file = request.files.get("audio")

    if audio_file:
        audio_file_size = len(audio_file.read())
        audio_file.seek(0)
        size_limit = 1 * 1024 * 1024

        if audio_file_size > size_limit:
            return jsonify({"error": "Audio file size exceeds 1MB. Not processing."})

        print("Audio received. Processing...")
        original_audio_dir = pathlib.Path("audio-input/original")
        converted_audio_dir = pathlib.Path("audio-input/converted")
        original_audio_dir.mkdir(parents=True, exist_ok=True)
        converted_audio_dir.mkdir(parents=True, exist_ok=True)

        existing_files = list(original_audio_dir.glob("*.wav"))
        print(f"Existing files in original directory: {existing_files}")
        next_file_num = len(existing_files) + 1
        temp_filename = original_audio_dir / f"audio_{next_file_num}.wav"

        audio_file.save(temp_filename)
        print(f"Saved new audio file as: {temp_filename}")

        converted_filename = (
            converted_audio_dir / f"converted_audio_{next_file_num}.wav"
        )
        result = subprocess.run(
            ["ffmpeg", "-i", str(temp_filename), str(converted_filename)],
            capture_output=True,
            text=True,
        )

        if result.returncode != 0:
            return jsonify({"error": "Audio conversion failed."})

        if not converted_filename.exists():
            return jsonify({"error": "Converted audio file not found."})

        with open(converted_filename, "rb") as f:
            response = openai.Audio.transcribe("whisper-1", f)
            transcribed_text = response["text"]
            print("Transcription completed:", transcribed_text)

            # Preprocess the transcribed_text
            transcribed_text = preprocess_text(transcribed_text)

            # Compare the transcribed audio with each choice
            accuracies = {}
            for key in request.form.keys():
                if key.startswith("choice_"):
                    choice_text = request.form.get(key)
                    accuracy = calculate_accuracy(choice_text, transcribed_text)
                    accuracies[key] = accuracy
                    print(
                        f"Comparing with {choice_text}"
                    )  # <-- This line prints the choice text
                    print(f"Calculated Accuracy for {key}: {accuracy}")

            # Determine which choice is closer to the transcription
            closest_choice = max(accuracies, key=accuracies.get)
            closest_choice_accuracy = accuracies[closest_choice]
            print(f"Closest Choice: {closest_choice}")

            return jsonify(
                {
                    "transcript": transcribed_text,
                    "accuracies": accuracies,
                    "closest_choice_id": closest_choice,  # Return the ID of the button element
                    "closest_choice_accuracy": closest_choice_accuracy,
                }
            )

    return jsonify({"error": "No audio received."})


@app.route("/check-accuracy", methods=["POST"])
def check_accuracy_route():
    original_text = request.form.get("originalText", "")
    transcript = request.form.get("transcript", "")
    print(f"Original Text: {original_text}")
    print(f"Transcript: {transcript}")
    accuracy = calculate_accuracy(original_text, transcript)
    print(f"Calculated Accuracy: {accuracy}")
    return jsonify({"accuracy": accuracy})


if __name__ == "__main__":
    app.run(debug=True, port=5001)


===== static/js/scripts.js =====
// Create a new Image object to load the low-quality image.
const lowQualityImage = new Image();

// This will log when the low-quality image starts loading.
console.log("Starting to load the low-quality image...");

// Hide the body initially
document.body.style.display = "none";

// Add an onload handler for the low-quality image.
lowQualityImage.onload = function () {
  console.log("Low-quality image has finished loading!");

  // Show the body once the low-quality image is fully loaded
  document.body.style.display = "block";

  // Delay the opacity change by 100ms to ensure the contentWrapper has rendered
  setTimeout(function () {
    const contentWrapper = document.getElementById("contentWrapper");
    contentWrapper.style.opacity = "1"; // This will fade in the contentWrapper using the CSS transition
  }, 100);

  // Now start loading the high-res image
  loadHighResImage();
};

// ... Rest of the existing code ...

// ... Previous code ...

function fadeOutBeforeNavigationChoice(sceneLink) {
  const url = "/?scene=" + sceneLink;
  fadeOutBeforeNavigation(url);
}

// Add the fade-out animation
const style = document.createElement("style");
style.innerHTML = `
  @keyframes blurAndFadeToWhite {
    0% {
      backdrop-filter: blur(0%);
      background-color: rgba(255, 255, 255, 0);
      opacity: 0;
    }
    100% {
      backdrop-filter: blur(10px);
      background-color: rgba(255, 255, 255, 1);
      opacity: 1;
    }
  }
`;
document.head.appendChild(style);

// ... Rest of the existing code ...

// ... Rest of the existing code ...

// Start by loading the low-quality image immediately when the script runs.
const sceneIdElement = document.getElementById("sceneId");
const sceneId = sceneIdElement.getAttribute("data-scene-id");
const lowResImageURL =
  "https://storyscenes.blob.core.windows.net/background-small/" +
  sceneId +
  ".jpg";
lowQualityImage.src = lowResImageURL;

function loadHighResImage() {
  // Create a new Image object to load the high-quality image.
  const highQualityImage = new Image();

  // This will log when the high-quality image starts loading.
  console.log("Starting to load the high-quality image...");

  // Add an onload handler for this image.
  highQualityImage.onload = function () {
    console.log("High-quality image has finished loading!");
    // Once the high-quality image is fully loaded, set it as the background.
    document.body.style.backgroundImage = "url(" + highQualityImage.src + ")";
  };

  // Add an onerror handler in case the high-quality image fails to load.
  highQualityImage.onerror = function () {
    console.error("Error loading the high-quality image.");
  };

  // Load the high-quality image.
  highQualityImage.src =
    "https://storyscenes.blob.core.windows.net/background-normal/" +
    sceneId +
    ".jpg";
}

document.addEventListener("keydown", function (event) {
  if (event.code === "Space") {
    const recordButton = document.getElementById("recordButton");
    if (recordButton.innerText === "Continue") {
      navigateToHighlightedChoice();
    } else {
      toggleRecording();
    }
    event.preventDefault();
  }
});

document.getElementById("recordButton").addEventListener("click", function () {
  if (this.innerText === "Continue") {
    navigateToHighlightedChoice();
  }
});

let mediaRecorder;
let audioChunks = [];
let isRecording = false;
let recordingTimer;

function toggleRecording() {
  isRecording ? stopAndTranscribe() : startRecording();
}

function startRecording() {
  navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
    initializeMediaRecorder(stream);
    mediaRecorder.start();
    updateUIForRecording();
    recordingTimer = setTimeout(() => {
      if (isRecording) {
        alert("Reached 25 seconds limit! Stopping recording.");
        cancelRecording();
      }
    }, 25000);
  });
}

function fadeOutBeforeNavigation(url) {
  // Check if the blurOverlay is already present (to prevent double blur)
  if (document.getElementById("outgoingBlurOverlay")) return;

  // Apply the fade-out animation to the contentWrapper
  const contentWrapper = document.getElementById("contentWrapper");
  contentWrapper.classList.add("fadeOutAnimation");

  // Create and append the blurOverlay for the blur effect
  const blurOverlay = document.createElement("div");
  blurOverlay.id = "outgoingBlurOverlay";
  blurOverlay.style.position = "fixed";
  blurOverlay.style.top = "0";
  blurOverlay.style.left = "0";
  blurOverlay.style.width = "100vw";
  blurOverlay.style.height = "100vh";
  blurOverlay.style.backdropFilter = "blur(0%)";
  blurOverlay.style.zIndex = "9999";
  blurOverlay.style.pointerEvents = "none";
  blurOverlay.style.opacity = "0";
  blurOverlay.style.animation = "blurFadeIn 1s forwards";

  document.body.appendChild(blurOverlay);

  // Navigate immediately
  window.location.href = url;
}
//

function initializeMediaRecorder(stream) {
  audioChunks = [];
  mediaRecorder = new MediaRecorder(stream);
  mediaRecorder.ondataavailable = (event) => {
    audioChunks.push(event.data);
  };
}

function updateUIForRecording() {
  document.getElementById("recordButton").innerText = "Stop Recording";
  isRecording = true;
}

function stopAndTranscribe() {
  clearTimeout(recordingTimer);
  mediaRecorder.onstop = processTranscription;
  mediaRecorder.stop();
  cleanupMediaRecorder();
}

function cancelRecording() {
  clearTimeout(recordingTimer);
  cleanupMediaRecorder();
  document.getElementById("recordButton").innerText = "Record";
  isRecording = false;
}

function cleanupMediaRecorder() {
  let tracks = mediaRecorder.stream.getTracks();
  tracks.forEach((track) => track.stop());
}

let isTranscribing = false;

function processTranscription() {
  document.getElementById("recordButton").innerText = "Transcribing...";
  isTranscribing = true; // Set the flag to true
  isRecording = false;

  sendAudioForTranscription().then((data) => {
    displayTranscriptionResults(data);
  });
}

function sendAudioForTranscription() {
  const audioBlob = new Blob(audioChunks);
  console.log("Sending audio for transcription...");

  const formData = new FormData();
  formData.append("audio", audioBlob);

  // Extracting choices from the rendered scene
  const choiceButtons = document.querySelectorAll("#choiceButtons button");
  choiceButtons.forEach((button, index) => {
    formData.append(`choice_${index + 1}`, button.innerText);
  });

  return fetch("/transcribe-audio", {
    method: "POST",
    body: formData,
  }).then((response) => response.json());
}

function displayTranscriptionResults(data) {
  document.getElementById(
    "transcriptResult",
  ).innerText = `Recording: ${data.transcript}`;
  isTranscribing = false; // Set the flag back to false
  console.log("Transcript from Whisper:", data.transcript);

  // Reset borders for all choices
  const choiceButtons = document.querySelectorAll("#choiceButtons button");
  choiceButtons.forEach((button) => {
    button.style.border = "none";
  });

  // Highlight the closest choice with a neon green border only if accuracy is not red
  console.log(data.closest_choice_id);
  if (data.closest_choice_accuracy !== 1) {
    const closestChoiceButton = document.getElementById(data.closest_choice_id);
    if (closestChoiceButton) {
      closestChoiceButton.style.border = "3px solid #39FF14"; // Neon
    }
  }

  let accuracyResult = document.getElementById("accuracyResult");
  accuracyResult.innerHTML = `Accuracy:&nbsp;&nbsp;${getAccuracyEmoji(
    data.closest_choice_accuracy,
  )}`;

  // Update the Record button's text based on the accuracy
  const recordButton = document.getElementById("recordButton");
  if (
    data.closest_choice_accuracy === 3 ||
    data.closest_choice_accuracy === 2
  ) {
    recordButton.innerText = "Continue";
    recordButton.onclick = function () {
      navigateToHighlightedChoice();
    };
  } else {
    recordButton.innerText = "Record";
    recordButton.onclick = function () {
      toggleRecording();
    };
  }
}

function navigateToHighlightedChoice() {
  const closestChoiceButton = document.querySelector(
    "#choiceButtons button[style='border: 3px solid rgb(57, 255, 20);']",
  );
  if (closestChoiceButton) {
    const sceneLink = closestChoiceButton.getAttribute("data-link");
    fadeOutBeforeNavigationChoice(sceneLink);
  }
}

// Add event listeners to the choice buttons to handle navigation
document.querySelectorAll("#choiceButtons button").forEach((button) => {
  button.addEventListener("click", function () {
    const sceneLink = button.getAttribute("data-link");
    fadeOutBeforeNavigationChoice(sceneLink);
  });
});
window.addEventListener("load", function () {
  setTimeout(function () {
    const blurOverlay = document.getElementById("blurOverlay");
    if (blurOverlay) {
      blurOverlay.remove();
    }
  }, 1000); // 1 second
});

// Add event listeners to the choice buttons to handle navigation
document.querySelectorAll("#choiceButtons button").forEach((button) => {
  button.addEventListener("click", function () {
    const targetURL = `/?scene=${button.getAttribute("data-link")}`;
    fadeOutBeforeNavigation(targetURL);
  });
});

function getAccuracyEmoji(accuracy) {
  if (accuracy === 3) return "🟢";
  if (accuracy === 2) return "🟡";
  return "🔴";
}


===== templates/index.html =====
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Accuracy Checker</title>
    <link rel="stylesheet" href="static/css/styles.css">
    <style>
        body {
            background-image: url('https://storyscenes.blob.core.windows.net/background-small/{{ scene_id }}.jpg');
        }
    </style>
</head>
<body>
    <div id="blurOverlay"></div> <!-- Here's the blur overlay div -->

    <!-- Hidden div to store scene_id for JavaScript to access -->
    <div id="sceneId" data-scene-id="{{ scene_id }}" style="display: none;"></div>

    <div id="contentWrapper">
        <p id="sceneText">{{ scene.text }}</p>
        <div id="choiceButtons">
            {% for choice in scene.choices %}
            <button id="choice_{{ loop.index }}" data-link="{{ choice.link }}" onclick="navigateToChoice(this)">
                {{ choice.text }}
            </button>
            {% endfor %}
        </div>
        <p id="transcriptResult">Recording: </p>
        <p id="accuracyResult">Accuracy:&nbsp;&nbsp;----</p>
        <button id="recordButton" onclick="toggleRecording()">Record</button>
    </div>
    <script src="static/js/scripts.js"></script>
</body>
</html>


===== utils/calculate_accuracy.py =====
import string
import re

# commit


def preprocess_text(text):
    # Remove characters not in the specified range
    text = re.sub(
        r"[^a-zA-Z\s"
        + string.punctuation
        + "áéíóúÁÉÍÓÚüÜñÑçÇöÖäÄëËïÏâêîôûÂÊÎÔÛàèìòùÀÈÌÒÙ]",
        "",
        text,
    )
    return text


def calculate_word_accuracy(original_words, transcript_words):
    total_words = len(original_words)
    matching_weight = 0

    # Clone the lists to not modify the original lists during removals
    original_clone = original_words.copy()
    transcript_clone = transcript_words.copy()

    # Check for exact matches first
    for o in original_clone:
        if o in transcript_clone:
            matching_weight += 1
            transcript_clone.remove(o)

    # Check for partial matches among the unmatched words
    for o in [word for word in original_clone if word not in transcript_clone]:
        if len(o) > 3:  # Only consider longer words for partial matches
            for t in transcript_clone:
                common_chars = sum(1 for char in o if char in t)
                overlap_percent = common_chars / len(o)
                if overlap_percent >= 0.7:  # Threshold for partial matches
                    matching_weight += overlap_percent
                    transcript_clone.remove(t)
                    break

    # Further adjusting the penalty factor using a more aggressive approach
    missing_words = total_words - matching_weight
    base_penalty = 0.1
    dynamic_penalty = base_penalty * (10 / (total_words + 1))
    penalty_factor = 1 - (base_penalty + dynamic_penalty) * missing_words

    # Ensure word accuracy doesn't go below 0%
    return max(
        0, min(1, (matching_weight / total_words) * penalty_factor)
    )  # Ensure it doesn't exceed 100%


def longest_common_subsequence(X, Y):
    m = len(X)
    n = len(Y)
    L = [[0] * (n + 1) for i in range(m + 1)]
    for i in range(m + 1):
        for j in range(n + 1):
            if i == 0 or j == 0:
                L[i][j] = 0
            elif X[i - 1] == Y[j - 1]:
                L[i][j] = L[i - 1][j - 1] + 1
            else:
                L[i][j] = max(L[i - 1][j], L[i][j - 1])
    return L[m][n]


def calculate_order_accuracy(original_words, transcript_words):
    lcs = longest_common_subsequence(original_words, transcript_words)
    return lcs / len(original_words)


def preprocess_for_comparison(text):
    """Removes punctuation and converts text to lowercase."""
    text = text.lower()
    # Remove punctuation
    text = "".join(ch for ch in text if ch not in set(string.punctuation))
    return text


def calculate_accuracy(original_text, transcript):
    original_text = preprocess_for_comparison(original_text)
    transcript = preprocess_for_comparison(transcript)
    original_words = original_text.split()
    transcript_words = transcript.split()
    word_accuracy = calculate_word_accuracy(original_words, transcript_words)
    order_accuracy = calculate_order_accuracy(original_words, transcript_words)
    overall_accuracy = round((0.8 * word_accuracy + 0.2 * order_accuracy), 2)
    print(
        f"Word Accuracy: {word_accuracy*100:.2f}% (Weighted Matching Words: {word_accuracy*len(original_words):.2f}/{len(original_words)})"
    )
    print(
        f"Order Accuracy: {order_accuracy*100:.2f}% (Correct Order Matches: {order_accuracy*len(original_words):.2f}/{len(original_words)})"
    )
    print(f"Overall Accuracy: {overall_accuracy*100:.2f}%")

    lower_threshold = 0.40
    upper_threshold = 0.85
    if 0 <= overall_accuracy <= lower_threshold:
        return 1
    elif lower_threshold <= overall_accuracy <= upper_threshold:
        return 2
    else:
        return 3


